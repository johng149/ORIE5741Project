{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 8\n",
    "num_heads = 4\n",
    "# mock embedding matrix 1\n",
    "seq_len1 = 6\n",
    "matrix1 = torch.randn(seq_len1, dim)\n",
    "# mock embedding matrix 2\n",
    "seq_len2 = 4\n",
    "matrix2 = torch.randn(seq_len2, dim)\n",
    "# ensure matrices only contain non-negative values\n",
    "matrix1 = torch.abs(matrix1)\n",
    "matrix2 = torch.abs(matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets1 = torch.tensor([-1,-1,4,-1,-1,2])\n",
    "targets2 = torch.tensor([-1,1,-1,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [targets1, targets2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, target in enumerate(targets):\n",
    "    targets[i] = torch.roll(target,-1)\n",
    "    targets[i][-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/john/Secondary/Documents/Cornell/Spring 2024/ORIE 4741 Learning From Data/Project/proj/lib64/python3.11/site-packages/torch/nested/__init__.py:166: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
      "  return _nested.nested_tensor(\n"
     ]
    }
   ],
   "source": [
    "targets = torch.nested.nested_tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.nested.to_padded_tensor(targets, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1,  4, -1, -1,  2, -1],\n",
       "        [ 1, -1,  8, -1, -1, -1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = [matrix1, matrix2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_seq_len = max([matrix.size(0) for matrix in matrices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lens = [matrix.size(0) for matrix in matrices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(matrices)):\n",
    "    m = matrices[i]\n",
    "    matrices[i] = pad(m, (0, 0, 0, longest_seq_len - m.size(0)), value=-100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices[-1][-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import scaled_dot_product_attention as sdpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_matrices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_attn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(seq_lens)):\n",
    "    causal_mask = torch.tril(torch.ones(longest_seq_len, longest_seq_len), diagonal=0)\n",
    "    causal_mask[:, seq_lens[i]: ] = 0\n",
    "    attn_matrices.append(causal_mask.bool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(seq_lens)):\n",
    "    causal_mask = torch.tril(torch.ones(longest_seq_len, longest_seq_len), diagonal=0)\n",
    "    naive_attn.append(causal_mask.bool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_matrices = torch.stack(attn_matrices)\n",
    "naive_attn = torch.stack(naive_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = torch.stack(matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.rand_like(matrices)\n",
    "k = torch.rand_like(matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, _, _ = q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = q.reshape(batch_size, -1, num_heads, dim // num_heads).transpose(1, 2)\n",
    "k = k.reshape(batch_size, -1, num_heads, dim // num_heads).transpose(1, 2)\n",
    "matrices = matrices.reshape(batch_size, -1, num_heads, dim // num_heads).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 6, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_attn.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sdpa(q, k, matrices, naive_attn.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.transpose(1, 2).reshape(batch_size, -1, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.6287e-01,  1.3786e-01,  2.0032e-01,  2.2771e-01,  1.5119e+00,\n",
       "           4.4166e-01,  2.5498e-01,  9.5068e-01],\n",
       "         [ 4.9620e-01,  2.4639e-01,  5.2187e-01,  8.2923e-01,  1.2061e+00,\n",
       "           7.7659e-01,  5.4411e-01,  8.0955e-01],\n",
       "         [ 9.7245e-01,  3.5233e-01,  5.0575e-01,  7.1621e-01,  9.9523e-01,\n",
       "           5.7724e-01,  3.8290e-01,  8.0256e-01],\n",
       "         [ 9.1522e-01,  3.7262e-01,  5.9163e-01,  7.5641e-01,  8.5354e-01,\n",
       "           4.9160e-01,  3.0517e-01,  7.6057e-01],\n",
       "         [ 8.0088e-01,  3.0581e-01,  5.5612e-01,  9.0470e-01,  1.0917e+00,\n",
       "           5.2244e-01,  4.9384e-01,  7.2574e-01],\n",
       "         [ 1.0317e+00,  2.8492e-01,  4.6904e-01,  8.9598e-01,  1.0835e+00,\n",
       "           5.0393e-01,  4.9092e-01,  6.5122e-01]],\n",
       "\n",
       "        [[ 3.2964e-01,  2.3999e-01,  5.2253e-01,  5.7660e-02,  1.1783e-01,\n",
       "           1.5077e-01,  2.0024e+00,  2.1966e+00],\n",
       "         [ 6.5230e-01,  2.0640e-01,  7.9830e-01,  2.8336e-01,  6.3062e-01,\n",
       "           6.2042e-01,  1.2868e+00,  1.5446e+00],\n",
       "         [ 6.0839e-01,  4.3707e-01,  1.1620e+00,  4.2502e-01,  4.9352e-01,\n",
       "           6.6201e-01,  1.0227e+00,  1.3305e+00],\n",
       "         [ 9.5420e-01,  3.2888e-01,  1.1881e+00,  6.9169e-01,  4.0732e-01,\n",
       "           6.7095e-01,  9.4989e-01,  1.0420e+00],\n",
       "         [-1.9400e+04, -1.9401e+04, -1.9387e+04, -1.9388e+04, -2.0683e+04,\n",
       "          -2.0683e+04, -1.7608e+04, -1.7607e+04],\n",
       "         [-1.8631e+04, -1.8631e+04, -1.7598e+04, -1.7599e+04, -1.5954e+04,\n",
       "          -1.5954e+04, -1.7056e+04, -1.7056e+04]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 6])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_matrices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = sdpa(q, k, matrices, attn_matrices.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result2.transpose(1, 2).reshape(batch_size, -1, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6629, 0.1379, 0.2003, 0.2277, 1.5119, 0.4417, 0.2550, 0.9507],\n",
       "         [0.4962, 0.2464, 0.5219, 0.8292, 1.2061, 0.7766, 0.5441, 0.8095],\n",
       "         [0.9725, 0.3523, 0.5057, 0.7162, 0.9952, 0.5772, 0.3829, 0.8026],\n",
       "         [0.9152, 0.3726, 0.5916, 0.7564, 0.8535, 0.4916, 0.3052, 0.7606],\n",
       "         [0.8009, 0.3058, 0.5561, 0.9047, 1.0917, 0.5224, 0.4938, 0.7257],\n",
       "         [1.0317, 0.2849, 0.4690, 0.8960, 1.0835, 0.5039, 0.4909, 0.6512]],\n",
       "\n",
       "        [[0.3296, 0.2400, 0.5225, 0.0577, 0.1178, 0.1508, 2.0024, 2.1966],\n",
       "         [0.6523, 0.2064, 0.7983, 0.2834, 0.6306, 0.6204, 1.2868, 1.5446],\n",
       "         [0.6084, 0.4371, 1.1620, 0.4250, 0.4935, 0.6620, 1.0227, 1.3305],\n",
       "         [0.9542, 0.3289, 1.1881, 0.6917, 0.4073, 0.6709, 0.9499, 1.0420],\n",
       "         [0.9639, 0.2970, 1.1933, 0.7012, 0.3663, 0.6422, 0.9855, 1.0241],\n",
       "         [0.9745, 0.3334, 1.1888, 0.6978, 0.3546, 0.6417, 0.9073, 0.9793]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_roll = torch.tensor([0,-1,-1,3,-1,-1,-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolled = torch.roll(before_roll,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1,  3, -1, -1, -1,  1,  0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolled[-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1,  3, -1, -1, -1,  1, -1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
